## Pluggable catalog (it has to extend org.apache.spark.sql.crossdata.XDCatalog)
## If there is no catalog class setted, DerbyCatalog will be used
#crossdata.catalog.class = "org.apache.spark.sql.crossdata.catalog.JDBCCatalog"

crossdata.catalog.caseSensitive = true
## List of Strings (Use quoation marks)
crossdata.catalog.args = []

#JDBC parameters

####### Example JDBC MySQL ###########
#crossdata.catalog.jdbc.driver = "com.mysql.jdbc.Driver"
#crossdata.catalog.jdbc.url = "jdbc:mysql://127.0.0.1:3306/"
#crossdata.catalog.jdbc.db.name = "crossdata"
#crossdata.catalog.jdbc.db.table = "crossdataTables"
#crossdata.catalog.jdbc.db.user = "root"
#crossdata.catalog.jdbc.db.pass = "root"

####### PostgreSQL ###########
#crossdata.catalog.jdbc.driver = "org.postgresql.Driver"
#crossdata.catalog.jdbc.url = "jdbc:postgresql://127.0.0.1:5432/"
#crossdata.catalog.jdbc.db.name = "crossdata"
#crossdata.catalog.jdbc.db.table = "crossdataTables"
#crossdata.catalog.jdbc.db.user = "postgres"
#crossdata.catalog.jdbc.db.pass = "postgres"
